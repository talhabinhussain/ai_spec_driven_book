"use strict";(self.webpackChunkai_native_book=self.webpackChunkai_native_book||[]).push([[620],{1683:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>u});const s=JSON.parse('{"id":"module-4-vla/chapter-4-6-conversational-robots","title":"Chapter 4.6: Building Conversational Robots","description":"Overview","source":"@site/docs/module-4-vla/chapter-4-6-conversational-robots.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-4-6-conversational-robots","permalink":"/ai_spec_driven_book/docs/module-4-vla/chapter-4-6-conversational-robots","draft":false,"unlisted":false,"editUrl":"https://github.com/talhabinhussain/ai_spec_driven_book/tree/main/docs/module-4-vla/chapter-4-6-conversational-robots.mdx","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4.5: Action Primitives and Execution","permalink":"/ai_spec_driven_book/docs/module-4-vla/chapter-4-5-action-primitives"},"next":{"title":"Chapter 4.7: The Capstone Project - Autonomous Humanoid","permalink":"/ai_spec_driven_book/docs/module-4-vla/chapter-4-7-capstone-project"}}');var o=t(4848),i=t(8453);const r={sidebar_position:7},a="Chapter 4.6: Building Conversational Robots",l={},u=[{value:"Overview",id:"overview",level:2},{value:"Understanding Conversational AI",id:"understanding-conversational-ai",level:2},{value:"Key Components of Conversational Systems",id:"key-components-of-conversational-systems",level:3},{value:"Dialogue Management Systems",id:"dialogue-management-systems",level:2},{value:"Context Awareness and Memory",id:"context-awareness-and-memory",level:2},{value:"Multi-Turn Dialogue Management",id:"multi-turn-dialogue-management",level:2},{value:"Natural Language Generation",id:"natural-language-generation",level:2},{value:"Speech Synthesis Integration",id:"speech-synthesis-integration",level:2},{value:"Integration with LLMs for Conversational AI",id:"integration-with-llms-for-conversational-ai",level:2},{value:"Practical Example: Complete Conversational Robot",id:"practical-example-complete-conversational-robot",level:2},{value:"Gesture and Non-Verbal Communication",id:"gesture-and-non-verbal-communication",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Context Management",id:"1-context-management",level:3},{value:"2. Dialogue Flow",id:"2-dialogue-flow",level:3},{value:"3. Natural Language Generation",id:"3-natural-language-generation",level:3},{value:"4. Multi-Modal Interaction",id:"4-multi-modal-interaction",level:3},{value:"Common Pitfalls",id:"common-pitfalls",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"chapter-46-building-conversational-robots",children:"Chapter 4.6: Building Conversational Robots"})}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"Conversational robots represent the ultimate goal of natural human-robot interaction, enabling seamless communication through natural language. This chapter explores how to build sophisticated dialogue systems that can engage in multi-turn conversations, maintain context, handle interruptions, and provide natural responses. You'll learn to create robots that can understand user intent, manage dialogue flow, and provide helpful responses while executing complex tasks."}),"\n",(0,o.jsx)(n.h2,{id:"understanding-conversational-ai",children:"Understanding Conversational AI"}),"\n",(0,o.jsx)(n.p,{children:"Conversational AI systems for robotics combine several key components:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mermaid",children:"graph TB\n    A[User Input] --\x3e B[Speech Recognition]\n    B --\x3e C[Natural Language Understanding]\n    C --\x3e D[Dialogue Manager]\n    D --\x3e E[Action Execution]\n    E --\x3e F[Natural Language Generation]\n    F --\x3e G[Speech Synthesis]\n    G --\x3e H[Robot Response]\n    H --\x3e I[User Feedback]\n    I --\x3e D\n"})}),"\n",(0,o.jsx)(n.h3,{id:"key-components-of-conversational-systems",children:"Key Components of Conversational Systems"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Automatic Speech Recognition (ASR)"}),": Converting speech to text"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Natural Language Understanding (NLU)"}),": Extracting meaning from text"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Dialogue Management"}),": Managing conversation flow and context"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Natural Language Generation (NLG)"}),": Creating natural responses"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Text-to-Speech (TTS)"}),": Converting text to spoken responses"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"dialogue-management-systems",children:"Dialogue Management Systems"}),"\n",(0,o.jsx)(n.p,{children:"Effective dialogue management is crucial for maintaining coherent conversations:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom your_interfaces.msg import DialogueState  # Custom message\nimport json\n\nclass DialogueManagerNode(Node):\n    def __init__(self):\n        super().__init__('dialogue_manager')\n\n        # Initialize dialogue state\n        self.conversation_state = {}\n        self.dialogue_context = {}\n        self.user_profiles = {}\n\n        # ROS 2 interfaces\n        self.user_input_sub = self.create_subscription(String, 'user_input', self.user_input_callback, 10)\n        self.robot_response_pub = self.create_publisher(String, 'robot_response', 10)\n        self.dialogue_state_pub = self.create_publisher(DialogueState, 'dialogue_state', 10)\n\n        # Dialogue policies\n        self.dialogue_policies = {\n            'task_completion': TaskCompletionPolicy(),\n            'context_maintenance': ContextMaintenancePolicy(),\n            'error_recovery': ErrorRecoveryPolicy()\n        }\n\n        self.get_logger().info(\"Dialogue manager initialized\")\n\n    def user_input_callback(self, msg):\n        \"\"\"\n        Process user input and generate appropriate response\n        \"\"\"\n        user_input = msg.data\n        user_id = \"default_user\"  # In practice, identify user\n\n        # Update conversation state\n        self.update_conversation_state(user_id, user_input)\n\n        # Process input through dialogue manager\n        response = self.process_dialogue_turn(user_id, user_input)\n\n        # Publish response\n        response_msg = String()\n        response_msg.data = response\n        self.robot_response_pub.publish(response_msg)\n\n        # Update and publish dialogue state\n        self.publish_dialogue_state(user_id)\n\n    def update_conversation_state(self, user_id, user_input):\n        \"\"\"\n        Update conversation state with user input\n        \"\"\"\n        if user_id not in self.conversation_state:\n            self.conversation_state[user_id] = {\n                'turns': [],\n                'current_topic': None,\n                'task_in_progress': None,\n                'entities': {},\n                'context': {}\n            }\n\n        # Add new turn\n        turn = {\n            'timestamp': self.get_clock().now().to_msg(),\n            'speaker': 'user',\n            'text': user_input,\n            'intent': self.extract_intent(user_input),\n            'entities': self.extract_entities(user_input)\n        }\n\n        self.conversation_state[user_id]['turns'].append(turn)\n\n        # Update entities and context\n        self.conversation_state[user_id]['entities'].update(turn['entities'])\n        self.update_context(user_id, turn)\n\n    def process_dialogue_turn(self, user_id, user_input):\n        \"\"\"\n        Process a complete dialogue turn\n        \"\"\"\n        state = self.conversation_state[user_id]\n\n        # Determine dialogue act\n        dialogue_act = self.classify_dialogue_act(user_input, state)\n\n        # Apply dialogue policies\n        for policy_name, policy in self.dialogue_policies.items():\n            if policy.can_apply(state, dialogue_act):\n                response = policy.generate_response(state, dialogue_act)\n                if response:\n                    return response\n\n        # Default response generation\n        return self.generate_default_response(user_id, user_input)\n\n    def extract_intent(self, text):\n        \"\"\"\n        Extract intent from user input\n        \"\"\"\n        # In practice, use NLP models or rule-based systems\n        text_lower = text.lower()\n\n        # Simple intent classification\n        if any(word in text_lower for word in ['navigate', 'go to', 'move to', 'walk to']):\n            return 'navigation_request'\n        elif any(word in text_lower for word in ['pick up', 'grasp', 'get', 'take']):\n            return 'manipulation_request'\n        elif any(word in text_lower for word in ['hello', 'hi', 'hey', 'greetings']):\n            return 'greeting'\n        elif any(word in text_lower for word in ['bye', 'goodbye', 'see you', 'farewell']):\n            return 'farewell'\n        elif '?' in text:\n            return 'question'\n        else:\n            return 'command'\n\n    def extract_entities(self, text):\n        \"\"\"\n        Extract named entities from text\n        \"\"\"\n        # Simple entity extraction\n        entities = {}\n\n        # Location entities\n        locations = ['kitchen', 'living room', 'bedroom', 'office', 'bathroom', 'home base']\n        for loc in locations:\n            if loc in text.lower():\n                entities['location'] = loc\n\n        # Object entities\n        objects = ['cup', 'bottle', 'book', 'phone', 'keys', 'ball', 'toy']\n        for obj in objects:\n            if obj in text.lower():\n                entities['object'] = obj\n\n        return entities\n\n    def classify_dialogue_act(self, text, state):\n        \"\"\"\n        Classify the dialogue act of user input\n        \"\"\"\n        intent = self.extract_intent(text)\n        entities = self.extract_entities(text)\n\n        return {\n            'intent': intent,\n            'entities': entities,\n            'previous_context': state.get('current_topic'),\n            'task_in_progress': state.get('task_in_progress')\n        }\n\n    def update_context(self, user_id, turn):\n        \"\"\"\n        Update dialogue context based on turn\n        \"\"\"\n        state = self.conversation_state[user_id]\n\n        # Update current topic\n        if turn['intent'] in ['navigation_request', 'manipulation_request']:\n            state['current_topic'] = turn['intent']\n\n        # Update task in progress\n        if turn['intent'] in ['navigation_request', 'manipulation_request']:\n            state['task_in_progress'] = {\n                'type': turn['intent'],\n                'entities': turn['entities'],\n                'status': 'in_progress'\n            }\n\n    def generate_default_response(self, user_id, user_input):\n        \"\"\"\n        Generate default response when no specific policy applies\n        \"\"\"\n        intent = self.extract_intent(user_input)\n\n        if intent == 'greeting':\n            return self.generate_greeting_response(user_input)\n        elif intent == 'farewell':\n            return self.generate_farewell_response()\n        elif intent in ['navigation_request', 'manipulation_request']:\n            return self.generate_task_response(user_id, user_input)\n        elif intent == 'question':\n            return self.generate_question_response(user_input)\n        else:\n            return \"I understand. How can I help you?\"\n\n    def generate_greeting_response(self, user_input):\n        \"\"\"\n        Generate appropriate greeting response\n        \"\"\"\n        import random\n        greetings = [\n            \"Hello! How can I assist you today?\",\n            \"Hi there! What can I do for you?\",\n            \"Greetings! How may I help you?\",\n            \"Hello! I'm ready to help. What would you like me to do?\"\n        ]\n        return random.choice(greetings)\n\n    def generate_farewell_response(self):\n        \"\"\"\n        Generate appropriate farewell response\n        \"\"\"\n        import random\n        farewells = [\n            \"Goodbye! Feel free to call me if you need anything.\",\n            \"See you later! Have a great day!\",\n            \"Farewell! I'll be here if you need assistance.\",\n            \"Bye! It was nice talking with you.\"\n        ]\n        return random.choice(farewells)\n\n    def generate_task_response(self, user_id, user_input):\n        \"\"\"\n        Generate response for task-related requests\n        \"\"\"\n        entities = self.extract_entities(user_input)\n\n        if 'location' in entities:\n            return f\"Okay, I'll navigate to the {entities['location']}.\"\n        elif 'object' in entities:\n            return f\"I'll look for the {entities['object']} and help you with that.\"\n        else:\n            return \"I can help with that. Could you please specify what you'd like me to do?\"\n\n    def generate_question_response(self, user_input):\n        \"\"\"\n        Generate response for questions\n        \"\"\"\n        return \"I'm not sure I can answer that. Could you ask me something else?\"\n\n    def publish_dialogue_state(self, user_id):\n        \"\"\"\n        Publish current dialogue state\n        \"\"\"\n        state = self.conversation_state[user_id]\n        state_msg = DialogueState()\n        state_msg.user_id = user_id\n        state_msg.current_topic = state.get('current_topic', '')\n        state_msg.task_in_progress = json.dumps(state.get('task_in_progress', {}))\n        state_msg.entities = json.dumps(state.get('entities', {}))\n\n        self.dialogue_state_pub.publish(state_msg)\n"})}),"\n",(0,o.jsx)(n.h2,{id:"context-awareness-and-memory",children:"Context Awareness and Memory"}),"\n",(0,o.jsx)(n.p,{children:"Conversational robots need to maintain context across multiple turns:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class ContextAwareDialogueManager:\n    def __init__(self, node):\n        self.node = node\n        self.context_memory = {}\n        self.short_term_memory = {}\n        self.long_term_memory = {}\n\n    def update_context(self, user_id, turn):\n        \"\"\"\n        Update context memory with new turn\n        \"\"\"\n        if user_id not in self.context_memory:\n            self.context_memory[user_id] = {\n                'short_term': [],  # Last 5 turns\n                'long_term': [],   # All previous conversations\n                'entities': {},    # Named entities\n                'topics': [],      # Conversation topics\n                'preferences': {}  # User preferences\n            }\n\n        # Add turn to short-term memory\n        self.context_memory[user_id]['short_term'].append(turn)\n        if len(self.context_memory[user_id]['short_term']) > 5:\n            self.context_memory[user_id]['short_term'] = \\\n                self.context_memory[user_id]['short_term'][-5:]\n\n        # Update entities\n        self.context_memory[user_id]['entities'].update(turn['entities'])\n\n        # Update topics\n        if turn['intent'] not in self.context_memory[user_id]['topics']:\n            self.context_memory[user_id]['topics'].append(turn['intent'])\n\n    def get_context_summary(self, user_id):\n        \"\"\"\n        Get summary of current context\n        \"\"\"\n        if user_id not in self.context_memory:\n            return {}\n\n        context = self.context_memory[user_id]\n        return {\n            'current_entities': context['entities'],\n            'recent_topics': context['topics'][-3:],\n            'conversation_length': len(context['short_term']),\n            'user_preferences': context['preferences']\n        }\n\n    def resolve_coreference(self, user_id, text):\n        \"\"\"\n        Resolve pronouns and references to previous mentions\n        \"\"\"\n        context = self.get_context_summary(user_id)\n        entities = context.get('current_entities', {})\n\n        # Replace pronouns with known entities\n        text_resolved = text\n        if 'it' in text.lower() and entities:\n            # Find the most recently mentioned object\n            for entity_type, entity_value in entities.items():\n                text_resolved = text_resolved.replace('it', entity_value)\n                break\n\n        if 'there' in text.lower() and 'location' in entities:\n            text_resolved = text_resolved.replace('there', entities['location'])\n\n        return text_resolved\n\n    def maintain_long_term_memory(self, user_id, conversation_ended=False):\n        \"\"\"\n        Move conversation to long-term memory when appropriate\n        \"\"\"\n        if conversation_ended:\n            # Move short-term to long-term\n            if user_id in self.context_memory:\n                short_term = self.context_memory[user_id]['short_term']\n                self.context_memory[user_id]['long_term'].extend(short_term)\n\n                # Keep only recent conversations in long-term\n                if len(self.context_memory[user_id]['long_term']) > 50:\n                    self.context_memory[user_id]['long_term'] = \\\n                        self.context_memory[user_id]['long_term'][-50:]\n\n                # Clear short-term for new conversation\n                self.context_memory[user_id]['short_term'] = []\n"})}),"\n",(0,o.jsx)(n.h2,{id:"multi-turn-dialogue-management",children:"Multi-Turn Dialogue Management"}),"\n",(0,o.jsx)(n.p,{children:"Complex conversations require sophisticated dialogue management:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class MultiTurnDialogueManager:\n    def __init__(self, node):\n        self.node = node\n        self.dialogue_states = {}\n        self.dialogue_flows = self.define_dialogue_flows()\n\n    def define_dialogue_flows(self):\n        \"\"\"\n        Define common dialogue flows\n        \"\"\"\n        return {\n            'navigation_assistant': {\n                'states': [\n                    'request_location',\n                    'confirm_destination',\n                    'navigate',\n                    'arrive',\n                    'task_complete'\n                ],\n                'transitions': {\n                    'request_location': ['confirm_destination'],\n                    'confirm_destination': ['navigate', 'request_location'],\n                    'navigate': ['arrive'],\n                    'arrive': ['task_complete']\n                }\n            },\n            'object_search': {\n                'states': [\n                    'request_object',\n                    'search_object',\n                    'found_object',\n                    'grasp_object',\n                    'deliver_object',\n                    'task_complete'\n                ],\n                'transitions': {\n                    'request_object': ['search_object'],\n                    'search_object': ['found_object', 'request_object'],\n                    'found_object': ['grasp_object'],\n                    'grasp_object': ['deliver_object', 'found_object'],\n                    'deliver_object': ['task_complete']\n                }\n            }\n        }\n\n    def start_dialogue_flow(self, user_id, flow_name):\n        \"\"\"\n        Start a specific dialogue flow\n        \"\"\"\n        if flow_name in self.dialogue_flows:\n            self.dialogue_states[user_id] = {\n                'flow_name': flow_name,\n                'current_state': self.dialogue_flows[flow_name]['states'][0],\n                'flow_data': {},\n                'timestamp': self.node.get_clock().now().to_msg()\n            }\n            return True\n        return False\n\n    def process_in_flow(self, user_id, user_input):\n        \"\"\"\n        Process input within an active dialogue flow\n        \"\"\"\n        if user_id not in self.dialogue_states:\n            return None\n\n        state = self.dialogue_states[user_id]\n        flow_name = state['flow_name']\n        current_state = state['current_state']\n\n        # Handle input based on current state\n        if flow_name == 'navigation_assistant':\n            return self.handle_navigation_flow(user_id, current_state, user_input)\n        elif flow_name == 'object_search':\n            return self.handle_object_search_flow(user_id, current_state, user_input)\n\n        return None\n\n    def handle_navigation_flow(self, user_id, current_state, user_input):\n        \"\"\"\n        Handle navigation dialogue flow\n        \"\"\"\n        if current_state == 'request_location':\n            # Extract destination from user input\n            entities = self.node.extract_entities(user_input)\n            if 'location' in entities:\n                self.dialogue_states[user_id]['flow_data']['destination'] = entities['location']\n                self.transition_state(user_id, 'confirm_destination')\n                return f\"Should I navigate to the {entities['location']}?\"\n            else:\n                return \"Where would you like me to go?\"\n\n        elif current_state == 'confirm_destination':\n            if any(word in user_input.lower() for word in ['yes', 'okay', 'sure', 'go']):\n                destination = self.dialogue_states[user_id]['flow_data']['destination']\n                self.transition_state(user_id, 'navigate')\n                # Trigger navigation action\n                self.trigger_navigation(destination)\n                return f\"On my way to the {destination}!\"\n            elif any(word in user_input.lower() for word in ['no', 'cancel', 'stop']):\n                self.end_dialogue_flow(user_id)\n                return \"Okay, I won't navigate there.\"\n            else:\n                return \"Please confirm with yes or no.\"\n\n        elif current_state == 'navigate':\n            # Navigation is in progress, wait for completion\n            return \"I'm navigating to your destination.\"\n\n        elif current_state == 'arrive':\n            destination = self.dialogue_states[user_id]['flow_data']['destination']\n            self.transition_state(user_id, 'task_complete')\n            return f\"I've arrived at the {destination}. How else can I help?\"\n\n        return \"I'm not sure how to respond right now.\"\n\n    def handle_object_search_flow(self, user_id, current_state, user_input):\n        \"\"\"\n        Handle object search dialogue flow\n        \"\"\"\n        if current_state == 'request_object':\n            entities = self.node.extract_entities(user_input)\n            if 'object' in entities:\n                self.dialogue_states[user_id]['flow_data']['object'] = entities['object']\n                self.transition_state(user_id, 'search_object')\n                # Start object search\n                self.start_object_search(entities['object'])\n                return f\"I'll look for the {entities['object']}.\"\n            else:\n                return \"What object are you looking for?\"\n\n        elif current_state == 'search_object':\n            # Search in progress\n            return \"I'm searching for the object.\"\n\n        elif current_state == 'found_object':\n            obj = self.dialogue_states[user_id]['flow_data']['object']\n            self.transition_state(user_id, 'grasp_object')\n            return f\"I found the {obj}. Should I pick it up?\"\n\n        elif current_state == 'grasp_object':\n            if any(word in user_input.lower() for word in ['yes', 'okay', 'sure', 'grasp']):\n                obj = self.dialogue_states[user_id]['flow_data']['object']\n                self.transition_state(user_id, 'deliver_object')\n                # Trigger grasping action\n                self.trigger_grasping(obj)\n                return f\"I've picked up the {obj}. Where should I bring it?\"\n            else:\n                self.end_dialogue_flow(user_id)\n                return \"Okay, I won't pick it up.\"\n\n        return \"Processing your request...\"\n\n    def transition_state(self, user_id, new_state):\n        \"\"\"\n        Transition dialogue state\n        \"\"\"\n        if user_id in self.dialogue_states:\n            old_state = self.dialogue_states[user_id]['current_state']\n            self.node.get_logger().info(f\"Transitioning from {old_state} to {new_state}\")\n            self.dialogue_states[user_id]['current_state'] = new_state\n\n    def trigger_navigation(self, destination):\n        \"\"\"\n        Trigger navigation action\n        \"\"\"\n        # Publish navigation command\n        nav_msg = String()\n        nav_msg.data = f\"navigate_to:{destination}\"\n        self.node.action_pub.publish(nav_msg)\n\n    def start_object_search(self, object_name):\n        \"\"\"\n        Start object search action\n        \"\"\"\n        # Publish object search command\n        search_msg = String()\n        search_msg.data = f\"search_object:{object_name}\"\n        self.node.action_pub.publish(search_msg)\n\n    def trigger_grasping(self, object_name):\n        \"\"\"\n        Trigger grasping action\n        \"\"\"\n        # Publish grasping command\n        grasp_msg = String()\n        grasp_msg.data = f\"grasp_object:{object_name}\"\n        self.node.action_pub.publish(grasp_msg)\n\n    def end_dialogue_flow(self, user_id):\n        \"\"\"\n        End current dialogue flow\n        \"\"\"\n        if user_id in self.dialogue_states:\n            del self.dialogue_states[user_id]\n"})}),"\n",(0,o.jsx)(n.h2,{id:"natural-language-generation",children:"Natural Language Generation"}),"\n",(0,o.jsx)(n.p,{children:"Generating natural, contextually appropriate responses:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class NaturalLanguageGenerator:\n    def __init__(self, node):\n        self.node = node\n        self.response_templates = self.load_response_templates()\n\n    def load_response_templates(self):\n        """\n        Load response templates for different contexts\n        """\n        return {\n            \'acknowledgment\': [\n                "Okay, I\'ll do that.",\n                "Got it. I\'ll take care of it.",\n                "Understood. Working on it now.",\n                "Sure thing. I\'m on it."\n            ],\n            \'confirmation\': [\n                "I will {action} {object} in the {location}.",\n                "I\'m going to {action} {object} now.",\n                "Okay, I\'ll {action} {object} for you."\n            ],\n            \'error\': [\n                "I\'m sorry, I couldn\'t {action} {object}.",\n                "I had trouble {action} {object}.",\n                "I couldn\'t complete that task."\n            ],\n            \'clarification\': [\n                "Could you please specify {what}?",\n                "I need more information about {what}.",\n                "Can you clarify {what} for me?"\n            ]\n        }\n\n    def generate_response(self, intent, entities, context=None):\n        """\n        Generate appropriate response based on intent and entities\n        """\n        import random\n\n        if intent == \'navigation_request\':\n            if \'location\' in entities:\n                responses = [\n                    f"Okay, I\'ll navigate to the {entities[\'location\']}.",\n                    f"Sure, heading to the {entities[\'location\']} now.",\n                    f"On my way to the {entities[\'location\']}!"\n                ]\n                return random.choice(responses)\n            else:\n                return "Where would you like me to go?"\n\n        elif intent == \'manipulation_request\':\n            if \'object\' in entities:\n                responses = [\n                    f"I\'ll look for the {entities[\'object\']} and help you with that.",\n                    f"Okay, I\'ll find and {self.extract_action(intent)} the {entities[\'object\']}.",\n                    f"I can help with the {entities[\'object\']}."\n                ]\n                return random.choice(responses)\n            else:\n                return "What object would you like me to help with?"\n\n        elif intent == \'greeting\':\n            responses = [\n                "Hello! How can I assist you today?",\n                "Hi there! What can I do for you?",\n                "Greetings! I\'m ready to help."\n            ]\n            return random.choice(responses)\n\n        elif intent == \'question\':\n            return self.generate_question_response(entities, context)\n\n        else:\n            return random.choice(self.response_templates[\'acknowledgment\'])\n\n    def generate_question_response(self, entities, context):\n        """\n        Generate response for questions\n        """\n        import random\n\n        # Check if question is about robot capabilities\n        question_lower = entities.get(\'raw_input\', \'\').lower()\n        if any(word in question_lower for word in [\'can you\', \'are you able\', \'do you know\']):\n            responses = [\n                "I can help with navigation, object manipulation, and answering questions.",\n                "I\'m capable of moving around, picking up objects, and understanding commands.",\n                "I can assist with various tasks around the house."\n            ]\n            return random.choice(responses)\n\n        # Default question response\n        responses = [\n            "I\'m not sure I can answer that. Could you ask something else?",\n            "I don\'t have information about that topic.",\n            "That\'s a good question, but I\'m not equipped to answer it."\n        ]\n        return random.choice(responses)\n\n    def personalize_response(self, response, user_profile):\n        """\n        Personalize response based on user profile\n        """\n        if user_profile and user_profile.get(\'name\'):\n            response = response.replace("you", f"{user_profile[\'name\']}")\n\n        # Add personality based on user preferences\n        if user_profile and user_profile.get(\'communication_style\') == \'formal\':\n            response = response.replace("!", ".").replace("Okay", "Certainly")\n\n        return response\n'})}),"\n",(0,o.jsx)(n.h2,{id:"speech-synthesis-integration",children:"Speech Synthesis Integration"}),"\n",(0,o.jsx)(n.p,{children:"Integrating text-to-speech for spoken responses:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import pyttsx3\nimport asyncio\n\nclass SpeechSynthesisNode(Node):\n    def __init__(self):\n        super().__init__(\'speech_synthesis\')\n\n        # Initialize text-to-speech engine\n        self.tts_engine = pyttsx3.init()\n        self.setup_tts_properties()\n\n        # ROS 2 interfaces\n        self.text_sub = self.create_subscription(String, \'robot_response\', self.text_callback, 10)\n        self.speech_status_pub = self.create_publisher(String, \'speech_status\', 10)\n\n        self.get_logger().info("Speech synthesis node initialized")\n\n    def setup_tts_properties(self):\n        """\n        Configure TTS engine properties\n        """\n        # Set voice properties\n        voices = self.tts_engine.getProperty(\'voices\')\n        if voices:\n            self.tts_engine.setProperty(\'voice\', voices[0].id)  # Use first available voice\n\n        # Set speech rate\n        self.tts_engine.setProperty(\'rate\', 150)  # Words per minute\n\n        # Set volume\n        self.tts_engine.setProperty(\'volume\', 0.9)\n\n    def text_callback(self, msg):\n        """\n        Process text for speech synthesis\n        """\n        text = msg.data\n\n        # Check if text is a special command\n        if text.startswith(\'SPEAK:\'):\n            actual_text = text[6:]  # Remove \'SPEAK:\' prefix\n        else:\n            actual_text = text\n\n        # Speak the text\n        self.speak_text(actual_text)\n\n    def speak_text(self, text):\n        """\n        Speak the given text\n        """\n        try:\n            # Publish status\n            status_msg = String()\n            status_msg.data = f"speaking:{text[:50]}..."\n            self.speech_status_pub.publish(status_msg)\n\n            # Speak the text\n            self.tts_engine.say(text)\n            self.tts_engine.runAndWait()\n\n            # Publish completion status\n            status_msg.data = "speech_complete"\n            self.speech_status_pub.publish(status_msg)\n\n        except Exception as e:\n            self.get_logger().error(f"Error in speech synthesis: {e}")\n            error_msg = String()\n            error_msg.data = f"speech_error:{str(e)}"\n            self.speech_status_pub.publish(error_msg)\n\n    def speak_async(self, text):\n        """\n        Speak text asynchronously\n        """\n        def speak_in_thread():\n            try:\n                self.tts_engine.say(text)\n                self.tts_engine.runAndWait()\n            except Exception as e:\n                self.get_logger().error(f"Async speech error: {e}")\n\n        import threading\n        thread = threading.Thread(target=speak_in_thread, daemon=True)\n        thread.start()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"integration-with-llms-for-conversational-ai",children:"Integration with LLMs for Conversational AI"}),"\n",(0,o.jsx)(n.p,{children:"Using Large Language Models to enhance conversational capabilities:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.memory import ConversationBufferMemory\n\nclass LLMConversationalNode(Node):\n    def __init__(self):\n        super().__init__(\'llm_conversational\')\n\n        # Initialize LLM\n        self.llm = ChatOpenAI(\n            model_name="gpt-3.5-turbo",\n            temperature=0.7,\n            max_tokens=150\n        )\n\n        # Conversation memory\n        self.memory = ConversationBufferMemory(\n            memory_key="chat_history",\n            input_key="input",\n            output_key="output",\n            return_messages=True\n        )\n\n        # ROS 2 interfaces\n        self.user_input_sub = self.create_subscription(String, \'user_input\', self.user_input_callback, 10)\n        self.robot_response_pub = self.create_publisher(String, \'robot_response\', 10)\n\n        # Create conversation chain\n        self.conversation_prompt = ChatPromptTemplate.from_messages([\n            ("system", self.get_system_prompt()),\n            ("human", "{input}"),\n            ("ai", "{output}")\n        ])\n\n    def get_system_prompt(self):\n        """\n        System prompt for the conversational robot\n        """\n        return """\n        You are a helpful robotic assistant. You are polite, concise, and helpful.\n        You can help with:\n        1. Navigation tasks (moving to locations)\n        2. Object manipulation (picking up, placing objects)\n        3. Answering questions about your capabilities\n        4. Providing status updates\n\n        Always respond naturally and conversationally. If asked to perform a task,\n        acknowledge the request and indicate you\'ll perform it. Don\'t just say you\'ll do it,\n        also provide the appropriate ROS command if needed.\n        """\n\n    def user_input_callback(self, msg):\n        """\n        Process user input through LLM\n        """\n        user_input = msg.data\n\n        # Create prompt with context\n        prompt = self.conversation_prompt.format_messages(\n            input=user_input,\n            output=""\n        )\n\n        try:\n            # Generate response\n            response = self.llm(prompt)\n\n            # Update memory\n            self.memory.save_context(\n                {"input": user_input},\n                {"output": response.content}\n            )\n\n            # Publish response\n            response_msg = String()\n            response_msg.data = response.content\n            self.robot_response_pub.publish(response_msg)\n\n            self.get_logger().info(f"LLM response: {response.content[:50]}...")\n\n        except Exception as e:\n            self.get_logger().error(f"LLM error: {e}")\n            error_response = String()\n            error_response.data = "I\'m having trouble processing that right now. Could you try again?"\n            self.robot_response_pub.publish(error_response)\n\n    def reset_conversation(self):\n        """\n        Reset conversation memory\n        """\n        self.memory.clear()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"practical-example-complete-conversational-robot",children:"Practical Example: Complete Conversational Robot"}),"\n",(0,o.jsx)(n.p,{children:"Let's build a complete conversational robot system:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class ConversationalRobotNode(Node):\n    def __init__(self):\n        super().__init__('conversational_robot')\n\n        # Initialize components\n        self.dialogue_manager = DialogueManagerNode(self)\n        self.context_manager = ContextAwareDialogueManager(self)\n        self.multi_turn_manager = MultiTurnDialogueManager(self)\n        self.nlg = NaturalLanguageGenerator(self)\n        self.tts = SpeechSynthesisNode(self)\n        self.llm_conversational = LLMConversationalNode(self)\n\n        # ROS 2 interfaces\n        self.user_input_sub = self.create_subscription(String, 'user_input', self.user_input_callback, 10)\n        self.voice_command_sub = self.create_subscription(String, 'voice_command', self.voice_command_callback, 10)\n        self.robot_response_pub = self.create_publisher(String, 'robot_response', 10)\n\n        # State management\n        self.active_dialogues = {}\n        self.user_contexts = {}\n\n        self.get_logger().info(\"Conversational robot system initialized\")\n\n    def user_input_callback(self, msg):\n        \"\"\"\n        Main entry point for user input processing\n        \"\"\"\n        user_input = msg.data\n        user_id = \"default_user\"  # In practice, identify user\n\n        # Check if in active dialogue flow\n        if user_id in self.active_dialogues:\n            response = self.multi_turn_manager.process_in_flow(user_id, user_input)\n            if response:\n                self.publish_response(response)\n                return\n\n        # Process through dialogue manager\n        self.dialogue_manager.update_conversation_state(user_id, user_input)\n        response = self.dialogue_manager.process_dialogue_turn(user_id, user_input)\n\n        # Generate natural language response\n        if not response or response.startswith(\"I understand\"):\n            # Use LLM for more natural responses\n            response = self.generate_llm_response(user_input)\n\n        # Publish response\n        self.publish_response(response)\n\n        # Update context\n        self.context_manager.update_context(user_id, {\n            'text': user_input,\n            'response': response,\n            'timestamp': self.get_clock().now().to_msg()\n        })\n\n    def voice_command_callback(self, msg):\n        \"\"\"\n        Handle voice commands specifically\n        \"\"\"\n        command = msg.data\n        user_id = \"default_user\"\n\n        # Determine if this is a task command\n        if self.is_task_command(command):\n            # Start appropriate dialogue flow\n            if self.contains_navigation_intent(command):\n                self.multi_turn_manager.start_dialogue_flow(user_id, 'navigation_assistant')\n            elif self.contains_manipulation_intent(command):\n                self.multi_turn_manager.start_dialogue_flow(user_id, 'object_search')\n\n        # Process normally\n        self.user_input_callback(msg)\n\n    def is_task_command(self, text):\n        \"\"\"\n        Determine if text is a task command\n        \"\"\"\n        task_indicators = [\n            'go to', 'navigate to', 'move to', 'walk to',\n            'pick up', 'get', 'take', 'grasp',\n            'find', 'look for', 'search for',\n            'bring', 'deliver', 'carry'\n        ]\n        return any(indicator in text.lower() for indicator in task_indicators)\n\n    def contains_navigation_intent(self, text):\n        \"\"\"\n        Check if text contains navigation intent\n        \"\"\"\n        nav_indicators = ['go to', 'navigate to', 'move to', 'walk to', 'head to']\n        return any(indicator in text.lower() for indicator in nav_indicators)\n\n    def contains_manipulation_intent(self, text):\n        \"\"\"\n        Check if text contains manipulation intent\n        \"\"\"\n        manip_indicators = ['pick up', 'get', 'take', 'grasp', 'find', 'look for']\n        return any(indicator in text.lower() for indicator in manip_indicators)\n\n    def generate_llm_response(self, user_input):\n        \"\"\"\n        Generate response using LLM\n        \"\"\"\n        try:\n            # Use the LLM conversational node\n            prompt = f\"Human: {user_input}\\nAI:\"\n\n            # For this example, we'll use a simple approach\n            # In practice, you'd call the LLM properly\n            import random\n            responses = [\n                f\"I understand you said: {user_input}. How can I help?\",\n                f\"Thanks for telling me about {user_input}. What would you like me to do?\",\n                f\"I hear you. {user_input} - I can help with that.\"\n            ]\n            return random.choice(responses)\n        except:\n            return \"I understand. How can I assist you?\"\n\n    def publish_response(self, response):\n        \"\"\"\n        Publish response through all appropriate channels\n        \"\"\"\n        # Publish to response channel\n        response_msg = String()\n        response_msg.data = response\n        self.robot_response_pub.publish(response_msg)\n\n        # Also send to TTS\n        tts_msg = String()\n        tts_msg.data = f\"SPEAK:{response}\"\n        self.tts.text_sub.publish(tts_msg)  # This would be published to TTS system\n\n        self.get_logger().info(f\"Robot response: {response}\")\n\n    def handle_interruption(self, user_id, interruption):\n        \"\"\"\n        Handle conversation interruptions\n        \"\"\"\n        if user_id in self.active_dialogues:\n            current_flow = self.active_dialogues[user_id]\n            if interruption.lower() in ['stop', 'cancel', 'abort']:\n                self.multi_turn_manager.end_dialogue_flow(user_id)\n                self.publish_response(\"Okay, I've stopped the current task.\")\n            elif interruption.lower() in ['help', 'what are you doing']:\n                self.publish_response(\"I'm currently performing a task. Would you like me to stop?\")\n            else:\n                self.publish_response(\"I'm busy with a task right now. Please wait or say stop to interrupt.\")\n\n    def reset_conversation(self, user_id):\n        \"\"\"\n        Reset conversation for user\n        \"\"\"\n        if user_id in self.user_contexts:\n            del self.user_contexts[user_id]\n        if user_id in self.active_dialogues:\n            del self.active_dialogues[user_id]\n\n        # Reset LLM conversation\n        self.llm_conversational.reset_conversation()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"gesture-and-non-verbal-communication",children:"Gesture and Non-Verbal Communication"}),"\n",(0,o.jsx)(n.p,{children:"Adding non-verbal communication to make interactions more natural:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class NonVerbalCommunicationNode(Node):\n    def __init__(self):\n        super().__init__(\'non_verbal_comm\')\n\n        # Publishers for non-verbal actions\n        self.head_pub = self.create_publisher(JointState, \'/head_controller/commands\', 10)\n        self.led_pub = self.create_publisher(String, \'/led_commands\', 10)\n        self.display_pub = self.create_publisher(String, \'/display_commands\', 10)\n\n        # ROS 2 interfaces\n        self.emotion_sub = self.create_subscription(String, \'robot_emotion\', self.emotion_callback, 10)\n        self.response_sub = self.create_subscription(String, \'robot_response\', self.response_callback, 10)\n\n    def emotion_callback(self, msg):\n        """\n        Handle emotion-based non-verbal communication\n        """\n        emotion = msg.data.lower()\n\n        if emotion == \'happy\':\n            self.express_happy()\n        elif emotion == \'confused\':\n            self.express_confused()\n        elif emotion == \'listening\':\n            self.express_listening()\n        elif emotion == \'thinking\':\n            self.express_thinking()\n        elif emotion == \'acknowledging\':\n            self.express_acknowledging()\n\n    def response_callback(self, msg):\n        """\n        Add non-verbal communication based on response type\n        """\n        response = msg.data.lower()\n\n        if any(word in response for word in [\'hello\', \'hi\', \'greetings\']):\n            self.express_happy()\n        elif any(word in response for word in [\'sorry\', \'couldn\\\'t\', \'failed\']):\n            self.express_confused()\n        elif \'?\' in response or \'what\' in response:\n            self.express_thinking()\n\n    def express_happy(self):\n        """\n        Express happiness through non-verbal cues\n        """\n        # Move head in a friendly way\n        head_msg = JointState()\n        head_msg.name = [\'head_pan\', \'head_tilt\']\n        head_msg.position = [0.0, -0.2]  # Look slightly up\n        self.head_pub.publish(head_msg)\n\n        # Set LED to warm color\n        led_msg = String()\n        led_msg.data = "color:00ff00"  # Green\n        self.led_pub.publish(led_msg)\n\n        # Show happy face on display\n        display_msg = String()\n        display_msg.data = "emoji:smile"\n        self.display_pub.publish(display_msg)\n\n    def express_confused(self):\n        """\n        Express confusion through non-verbal cues\n        """\n        # Tilt head\n        head_msg = JointState()\n        head_msg.name = [\'head_pan\', \'head_tilt\']\n        head_msg.position = [0.0, 0.3]  # Tilt head\n        self.head_pub.publish(head_msg)\n\n        # Set LED to yellow\n        led_msg = String()\n        led_msg.data = "color:ffff00"  # Yellow\n        self.led_pub.publish(led_msg)\n\n        # Show confused face\n        display_msg = String()\n        display_msg.data = "emoji:confused"\n        self.display_pub.publish(display_msg)\n\n    def express_listening(self):\n        """\n        Express active listening\n        """\n        # Face user direction\n        head_msg = JointState()\n        head_msg.name = [\'head_pan\', \'head_tilt\']\n        head_msg.position = [0.0, 0.0]  # Center position\n        self.head_pub.publish(head_msg)\n\n        # Set LED to blue\n        led_msg = String()\n        led_msg.data = "color:0000ff"  # Blue\n        self.led_pub.publish(led_msg)\n\n        # Show listening indicator\n        display_msg = String()\n        display_msg.data = "text:Listening..."\n        self.display_pub.publish(display_msg)\n\n    def express_thinking(self):\n        """\n        Express thinking/processing\n        """\n        # Look up and to the side\n        head_msg = JointState()\n        head_msg.name = [\'head_pan\', \'head_tilt\']\n        head_msg.position = [0.5, 0.2]  # Look up and right\n        self.head_pub.publish(head_msg)\n\n        # Pulsing LED\n        led_msg = String()\n        led_msg.data = "pulsing:808080"  # Gray pulse\n        self.led_pub.publish(led_msg)\n\n        # Show thinking animation\n        display_msg = String()\n        display_msg.data = "animation:thinking"\n        self.display_pub.publish(display_msg)\n\n    def express_acknowledging(self):\n        """\n        Express acknowledgment\n        """\n        # Nod head\n        head_msg = JointState()\n        head_msg.name = [\'head_pan\', \'head_tilt\']\n        head_msg.position = [0.0, -0.1]  # Small nod\n        self.head_pub.publish(head_msg)\n\n        # Flash LED\n        led_msg = String()\n        led_msg.data = "flash:00ff00"  # Green flash\n        self.led_pub.publish(led_msg)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsx)(n.h3,{id:"1-context-management",children:"1. Context Management"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Maintain conversation history appropriately"}),"\n",(0,o.jsx)(n.li,{children:"Use both short-term and long-term memory"}),"\n",(0,o.jsx)(n.li,{children:"Resolve coreferences and pronouns correctly"}),"\n",(0,o.jsx)(n.li,{children:"Track user preferences and communication style"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"2-dialogue-flow",children:"2. Dialogue Flow"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Design clear dialogue states and transitions"}),"\n",(0,o.jsx)(n.li,{children:"Handle interruptions gracefully"}),"\n",(0,o.jsx)(n.li,{children:"Provide clear feedback on task progress"}),"\n",(0,o.jsx)(n.li,{children:"Use confirmation when appropriate"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"3-natural-language-generation",children:"3. Natural Language Generation"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Vary responses to avoid robotic repetition"}),"\n",(0,o.jsx)(n.li,{children:"Personalize based on user context"}),"\n",(0,o.jsx)(n.li,{children:"Keep responses concise but informative"}),"\n",(0,o.jsx)(n.li,{children:"Match the user's communication style"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"4-multi-modal-interaction",children:"4. Multi-Modal Interaction"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Combine speech with gestures and visual feedback"}),"\n",(0,o.jsx)(n.li,{children:"Use appropriate non-verbal cues"}),"\n",(0,o.jsx)(n.li,{children:"Synchronize verbal and non-verbal communication"}),"\n",(0,o.jsx)(n.li,{children:"Provide feedback through multiple channels"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"common-pitfalls",children:"Common Pitfalls"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"State Management"}),": Failing to maintain proper conversation state"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Context Loss"}),": Losing track of conversation context across turns"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Response Repetition"}),": Generating identical responses repeatedly"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Interruption Handling"}),": Not properly handling user interruptions"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Over-Reliance on LLMs"}),": Depending too heavily on LLMs without safety checks"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"In this chapter, you learned:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"\u2705 How to build comprehensive dialogue management systems"}),"\n",(0,o.jsx)(n.li,{children:"\u2705 Context awareness and memory management techniques"}),"\n",(0,o.jsx)(n.li,{children:"\u2705 Multi-turn conversation handling"}),"\n",(0,o.jsx)(n.li,{children:"\u2705 Natural language generation for robot responses"}),"\n",(0,o.jsx)(n.li,{children:"\u2705 Speech synthesis integration"}),"\n",(0,o.jsx)(n.li,{children:"\u2705 LLM integration for conversational AI"}),"\n",(0,o.jsx)(n.li,{children:"\u2705 Non-verbal communication and gestures"}),"\n",(0,o.jsx)(n.li,{children:"\u2705 Best practices for natural human-robot interaction"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(n.p,{children:"In our final chapter, we'll bring everything together in a comprehensive capstone project that integrates all VLA components into a complete autonomous humanoid system."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Continue to:"})," ",(0,o.jsx)(n.a,{href:"./chapter-4-7-capstone-project",children:"Chapter 4.7: The Capstone Project - Autonomous Humanoid \u2192"})]}),"\n",(0,o.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://spacy.io/",children:"SpaCy for Natural Language Processing"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://rasa.com/",children:"Rasa for Dialogue Management"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://cloud.google.com/dialogflow",children:"Google Dialogflow"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=10203",children:"Human-Robot Interaction Research"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://arxiv.org/abs/2304.13237",children:"Conversational AI Guidelines"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var s=t(6540);const o={},i=s.createContext(o);function r(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);